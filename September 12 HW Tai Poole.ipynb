{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c1a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7823cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c76836",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.github.com/ageron/handson-ml/raw/master/datasets/housing/housing.csv\"\n",
    "data = pd.read_csv(url)\n",
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf45f21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#1\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.isna().sum()\n",
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a827c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 20640 rows and 10 columns.\n"
     ]
    }
   ],
   "source": [
    "rows, columns = data.shape\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")\n",
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc0e724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n"
     ]
    }
   ],
   "source": [
    "summary = data.describe()\n",
    "print(summary)\n",
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dd3d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocean_proximity\n",
      "<1H OCEAN     9136\n",
      "INLAND        6551\n",
      "NEAR OCEAN    2658\n",
      "NEAR BAY      2290\n",
      "ISLAND           5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_counts = value_counts = data['ocean_proximity'].value_counts()\n",
    "print(column_counts)\n",
    "#3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd91b72e",
   "metadata": {},
   "source": [
    "4. I believe that the reason why data.describe() only shows 9 columns while my data.shape has 10 is due to the types of data in the columns. data.describe() provides numerical evaluations like the mean and the standard deviation, and these would not be posssible to compute for certain data types like strings and booleans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64831a",
   "metadata": {},
   "source": [
    "5. The main difference is what they do. An attribute (like data.shape) is a characteristics or \"adjectives\" of the object (which in this case is our dataframe). Meanwhile, a method is a like an action or a \"verb\" that you can do to gather some information about the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4c83d",
   "metadata": {},
   "source": [
    "6.\n",
    "count: counts the number of non zero entries\n",
    "mean: takes the sum of all the entries and divides it by the number of entries\n",
    "\n",
    "std: represents the variance of the data around the mean \n",
    "min:\n",
    "25%: the point where 25% of the data is lower and 75% is higher\n",
    "50%: the median of the data\n",
    "75%: the point where 75% of the data is lower and 25% is higher\n",
    "max: largest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f0fbb",
   "metadata": {},
   "source": [
    "7. del data['col'] and data.dropna() have different use cases based on amounts of data missing. I would use data.dropna() if there is a small amount of data missing from that column and it would not significantly alter the conclusions drawn by removing that portion. However, if there are large amounts of data missing, so much so that it would not be useful to include, then I would use del data['col'] to remove it. for example, I would probably use dropna() on total bedrooms to get rid of the small amount of missing data and del the ocean_proximity column since its non numeric and does not seem to contribute much to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60dff29",
   "metadata": {},
   "source": [
    "8.\n",
    "\n",
    "1. groupby takes the data provided and groups them together. after that, the set of square brackets refers to a single column in those groups, which is later described using the .describe() method giving you things like min, max, std, mean, etc\n",
    "2. this is because the count from just a data.describe() would include rows where there is other amounts of data present but not necessarily in the col2. when you group them, you automatically exclude values that are missing or null in that given column, leading to different accumulations\n",
    "3. \n",
    "    A. i think for a basic error like this its equally fast to use a chatbot or just find it on a website like stack overflow\n",
    "    B. i think that the chatbot is more thorough about common mistakes and ways to fix it, but google can be faster\n",
    "    C. this issue i found the chatbot to be faster\n",
    "    D. the chatbot is better here, because it can provide specific code analysis unlike something on a google search\n",
    "    E. although it provided a lot of help that wasn't very related to the issue, the chatbot did end up finding that there was a case sensitivity issue\n",
    "    F. for a simple syntax error like spelling, chatbot was much more helpful with finding it than google\n",
    "    G. i was able to find answers for this on stack overflow quite quickly\n",
    "    OVERALL. The chatbot can help with specific types of syntax errors like typos but for semantic issues you can probably look to use either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039c679",
   "metadata": {},
   "source": [
    "## SUMMARY\n",
    "Certainly! Here's a summary of what we discussed:\n",
    "\n",
    "Finding Dataset Dimensions:\n",
    "\n",
    "To find the number of rows and columns in a dataset using Pandas, load the CSV file and use the .shape attribute.\n",
    "Example:\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "data = pd.read_csv('your_dataset_url')\n",
    "rows, columns = data.shape\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")\n",
    "Summarizing Columns:\n",
    "\n",
    "Use the .describe() method to get a summary of numerical columns in the dataset, including count, mean, std, min, and percentiles.\n",
    "For a summary of all columns, use .describe(include='all').\n",
    "Example:\n",
    "python\n",
    "Copy code\n",
    "summary = data.describe(include='all')\n",
    "print(summary)\n",
    "Counting Values:\n",
    "\n",
    "To count non-null values in each column, use the .count() method.\n",
    "To count unique values in each column, use the .nunique() method.\n",
    "Example:\n",
    "python\n",
    "Copy code\n",
    "count_values = data.count()\n",
    "print(count_values)\n",
    "unique_counts = data.nunique()\n",
    "print(unique_counts)\n",
    "Counting Values in a Specific Column:\n",
    "\n",
    "Use .value_counts() to count occurrences of each unique value in a specific column.\n",
    "To count non-null values in a specific column, use .count() on that column.\n",
    "Example:\n",
    "python\n",
    "Copy code\n",
    "value_counts = data['column_name'].value_counts()\n",
    "print(value_counts)\n",
    "non_null_count = data['column_name'].count()\n",
    "print(non_null_count)\n",
    "Attributes vs. Methods:\n",
    "\n",
    "Attributes: Variables or properties of an object (e.g., color, model).\n",
    "Methods: Functions or actions associated with an object (e.g., drive(), honk()).\n",
    "Attributes are accessed directly (e.g., object.attribute), while methods are called with parentheses (e.g., object.method()).\n",
    "If you have any more questions or need further clarification, feel free to ask!\n",
    "\n",
    "## Link\n",
    "https://chatgpt.com/c/66df3e5b-37a0-8004-bb42-66e435a1966c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5d3e3",
   "metadata": {},
   "source": [
    "## Summary for 8.\n",
    "Here's a summary of the topics we discussed today:\n",
    "\n",
    "df.groupby(\"col1\")[\"col2\"].describe(): This code groups the DataFrame by the unique values of col1, then calculates summary statistics (like count, mean, and standard deviation) for col2 within each group.\n",
    "\n",
    "NameError: pd is not defined: This error occurs when the pandas library is not imported. The solution is to include import pandas as pd at the top of your script.\n",
    "\n",
    "FileNotFoundError: 'titanics.csv': This error arises when Python cannot locate the file you're trying to load. Ensure that the file name and path are correct. You can also load the Titanic dataset directly from the URL you provided using:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "NameError: df is not defined: This error means you're trying to use df before defining it. The solution is to load the data into df correctly before referencing it.\n",
    "\n",
    "Typo in code: data.isna(.sum(): The correct syntax should be data.isna().sum(). This checks for missing values in the DataFrame and sums them column-wise.\n",
    "\n",
    "Issue with missing Sex column: If you get an error saying the Sex column is missing, but itâ€™s visible in the data, possible reasons include a typo, incorrect capitalization, hidden whitespace, or using the wrong DataFrame. You can check column names using print(df.columns) and clean column names if needed using df.columns.str.strip().\n",
    "\n",
    "These steps should help you resolve the issues you're encountering while analyzing the Titanic dataset. Let me know if you have any further questions!\n",
    "\n",
    "## Link\n",
    "https://chatgpt.com/c/66e10a67-8cf4-8004-8130-6d710a72d540 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
